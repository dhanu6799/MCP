{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's experiment with a bunch more MCP Servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from agents import Agent, Runner, trace\n",
    "from agents.mcp import MCPServerStdio\n",
    "import os\n",
    "from IPython.display import Markdown, display\n",
    "from datetime import datetime\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first type of MCP Server: runs locally, everything local\n",
    "\n",
    "Here's a really interesting one: a knowledge-graph based memory.\n",
    "\n",
    "It's a persistent memory store of entities, observations about them, and relationships between them.\n",
    "\n",
    "https://github.com/modelcontextprotocol/servers/tree/main/src/memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from agents.mcp import MCPServerStdio\n",
    "\n",
    "# Base environment with Node.js in PATH\n",
    "def get_mcp_env(**extra_vars):\n",
    "    env = os.environ.copy()\n",
    "    env[\"PATH\"] = f\"/home/dneelapu/.nvm/versions/node/v22.21.0/bin:{env.get('PATH', '')}\"\n",
    "    env.update(extra_vars)\n",
    "    return env\n",
    "\n",
    "# For LibSQL Memory\n",
    "Path(\"./memory\").mkdir(exist_ok=True)\n",
    "params = {\n",
    "    \"command\": \"npx\",\n",
    "    \"args\": [\"mcp-memory-libsql\"],\n",
    "    \"env\": get_mcp_env(LIBSQL_URL=\"file:./memory/dhanu.db\")\n",
    "}\n",
    "\n",
    "async with MCPServerStdio(params=params, client_session_timeout_seconds=60) as server:\n",
    "    mcp_tools = await server.list_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"You use your entity tools as a persistent memory to store and recall information about your conversations.\"\n",
    "request = \"My name's Dhanu. I'm an AI Product engineer. I'm learning a course about AI Agents, including the incredible MCP protocol. \\\n",
    "MCP is a protocol for connecting agents with tools, resources and prompt templates, and makes it easy to integrate AI agents with capabilities.\"\n",
    "model = \"gpt-4.1-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Nice to meet you, Dhanu! It's great that you're learning about AI Agents and the MCP protocol. The MCP protocol sounds like a powerful way to connect AI agents with various tools and resources, making integrations smoother and more capable. If you have any questions or want to discuss anything specific about AI agents or MCP, feel free to ask!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "async with MCPServerStdio(params=params, client_session_timeout_seconds=30) as mcp_server:\n",
    "    agent = Agent(name=\"agent\", instructions=instructions, model=model, mcp_servers=[mcp_server])\n",
    "    with trace(\"conversation\"):\n",
    "        result = await Runner.run(agent, request)\n",
    "    display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You are Dhanu, an AI Product engineer. You are currently learning a course about AI Agents including the MCP protocol. Is there anything specific you would like me to remember or help you with regarding this?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "async with MCPServerStdio(params=params, client_session_timeout_seconds=30) as mcp_server:\n",
    "    agent = Agent(name=\"agent\", instructions=instructions, model=model, mcp_servers=[mcp_server])\n",
    "    with trace(\"conversation\"):\n",
    "        result = await Runner.run(agent, \"My name's dhanu. What do you know about me?\")\n",
    "    display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the trace:\n",
    "\n",
    "https://platform.openai.com/traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The 2nd type of MCP server - runs locally, calls a web service\n",
    "\n",
    "### Brave Search - apologies - this will need another API key! But it's free again.\n",
    "\n",
    "https://brave.com/search/api/\n",
    "\n",
    "Set up your account, and put your key in the .env under `BRAVE_API_KEY`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key exists: True\n",
      "Key length: 31\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "key = os.getenv(\"BRAVE_API_KEY\")\n",
    "print(f\"Key exists: {key is not None}\")\n",
    "print(f\"Key length: {len(key) if key else 0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tool(name='brave_web_search', title=None, description='Performs a web search using the Brave Search API, ideal for general queries, news, articles, and online content. Use this for broad information gathering, recent events, or when you need diverse web sources. Supports pagination, content filtering, and freshness controls. Maximum 20 results per request, with offset for pagination. ', inputSchema={'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'Search query (max 400 chars, 50 words)'}, 'count': {'type': 'number', 'description': 'Number of results (1-20, default 10)', 'default': 10}, 'offset': {'type': 'number', 'description': 'Pagination offset (max 9, default 0)', 'default': 0}}, 'required': ['query']}, outputSchema=None, icons=None, annotations=None, meta=None), Tool(name='brave_local_search', title=None, description=\"Searches for local businesses and places using Brave's Local Search API. Best for queries related to physical locations, businesses, restaurants, services, etc. Returns detailed information including:\\n- Business names and addresses\\n- Ratings and review counts\\n- Phone numbers and opening hours\\nUse this when the query implies 'near me' or mentions specific locations. Automatically falls back to web search if no local results are found.\", inputSchema={'type': 'object', 'properties': {'query': {'type': 'string', 'description': \"Local search query (e.g. 'pizza near Central Park')\"}, 'count': {'type': 'number', 'description': 'Number of results (1-20, default 5)', 'default': 5}}, 'required': ['query']}, outputSchema=None, icons=None, annotations=None, meta=None)]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from agents.mcp import MCPServerStdio\n",
    "\n",
    "# For Brave Search\n",
    "params = {\n",
    "    \"command\": \"npx\",\n",
    "    \"args\": [\"-y\", \"@modelcontextprotocol/server-brave-search\"],\n",
    "    \"env\": get_mcp_env(BRAVE_API_KEY=os.getenv(\"BRAVE_API_KEY\"))\n",
    "}\n",
    "\n",
    "async with MCPServerStdio(params=params, client_session_timeout_seconds=30) as server:\n",
    "    mcp_tools = await server.list_tools()\n",
    "\n",
    "print(mcp_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"You are able to search the web for information and briefly summarize the takeaways.\"\n",
    "request = f\"Please research the latest news on Amazon stock price and briefly summarize its outlook. \\\n",
    "For context, the current date is {datetime.now().strftime('%Y-%m-%d')}\"\n",
    "model = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here's a summary of the latest news and outlook for Amazon (AMZN) stock as of October 28, 2025:\n",
       "\n",
       "1. **Current Price Outlook**: The average stock price target from analysts is approximately **$266.26**, indicating about a **17.16% potential increase** from its current level.\n",
       "\n",
       "2. **Analyst Ratings**: Amazon stock has received a consensus rating of **\"Strong Buy\"** from 46 analysts, showing strong confidence in its performance over the next year. \n",
       "\n",
       "3. **Future Predictions**: Some forecasts predict a potential price of **$267.88** within the next year, reflecting positive sentiment towards the stock driven by favorable market conditions and strong business fundamentals.\n",
       "\n",
       "4. **Market Sentiment**: There is optimism regarding the stock's ability to break out further, as suggested by some analysts citing strong growth prospects.\n",
       "\n",
       "In summary, the outlook for Amazon stock appears positive, with predictions of continued upward momentum through late 2025 and into 2026."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "async with MCPServerStdio(params=params, client_session_timeout_seconds=60) as mcp_server:\n",
    "    agent = Agent(name=\"agent\", instructions=instructions, model=model, mcp_servers=[mcp_server])\n",
    "    with trace(\"conversation\"):\n",
    "        result = await Runner.run(agent, request)\n",
    "    display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As usual, check out the trace:\n",
    "\n",
    "https://platform.openai.com/traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And now the third type: running remotely\n",
    "\n",
    "It's actually really hard to find a \"remote MCP server\" aka \"hosted MCP server\" aka \"managed MCP server\".\n",
    "\n",
    "It's not a common model for using or sharing MCP servers, and there isn't a standard way to discover remote MCP servers.\n",
    "\n",
    "Anthropic lists some remote MCP servers, but these are for paid applications with business users:\n",
    "\n",
    "https://docs.anthropic.com/en/docs/agents-and-tools/remote-mcp-servers\n",
    "\n",
    "CloudFlare has tooling for you to create and deploy your own remote MCP servers, but this does not seem to be a common practice:\n",
    "\n",
    "https://developers.cloudflare.com/agents/guides/remote-mcp-server/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And back to the 2nd type: the Polygon.io MCP Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEW SECTION: Introducing polygon.io\n",
    "\n",
    "Polygon.io is a hugely popular financial data provider. It has a free plan and a paid plan. And it also has an MCP Server!\n",
    "\n",
    "First, read up on polygon.io on their excellent website, including looking at their pricing:\n",
    "\n",
    "https://polygon.io\n",
    "\n",
    "### Polygon.io Part 1: Polygon.io free service (the paid will be totally optional, of course!)\n",
    "\n",
    "1. Please sign up for polygon.io (top right)  \n",
    "2. Once signed in, please select \"Keys\" in the left hand navigation\n",
    "3. Press the blue \"New Key\" button\n",
    "4. Copy the key name\n",
    "5. Edit your .env file and add the row:\n",
    "\n",
    "`POLYGON_API_KEY=xxxx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "polygon_api_key = os.getenv(\"POLYGON_API_KEY\")\n",
    "if not polygon_api_key:\n",
    "    print(\"POLYGON_API_KEY is not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreviousCloseAgg(ticker='AAPL', close=268.81, high=269.12, low=264.6501, open=264.88, timestamp=1761595200000, volume=44888052.0, vwap=267.0053)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from polygon import RESTClient\n",
    "client = RESTClient(polygon_api_key)\n",
    "client.get_previous_close_agg(\"AAPL\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapped into a python module that caches end of day prices\n",
    "\n",
    "I've made a python module `market.py` that uses this API to look up share prices.\n",
    "\n",
    "But the free API is quite heavily rate limited - so I've been a bit sneaky; when you ask for a share price, this function retrieves the entire end-of-day equity market, and caches it in our database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268.81"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from market import get_share_price\n",
    "get_share_price(\"AAPL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268.81"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no rate limiting concerns!\n",
    "\n",
    "for i in range(1000):\n",
    "    get_share_price(\"AAPL\")\n",
    "get_share_price(\"AAPL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And I've made this into an MCP Server\n",
    "\n",
    "Just as we did with accounts.py; see `market_server.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tool(name='lookup_share_price', title=None, description='This tool provides the current price of the given stock symbol.\\n\\n    Args:\\n        symbol: the symbol of the stock\\n    ', inputSchema={'properties': {'symbol': {'title': 'Symbol', 'type': 'string'}}, 'required': ['symbol'], 'title': 'lookup_share_priceArguments', 'type': 'object'}, outputSchema=None, icons=None, annotations=None, meta=None)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\"command\": \"uv\", \"args\": [\"run\", \"market_server.py\"]}\n",
    "async with MCPServerStdio(params=params, client_session_timeout_seconds=60) as server:\n",
    "    mcp_tools = await server.list_tools()\n",
    "mcp_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try it out!\n",
    "\n",
    "Hopefully gpt-4o-mini is smart enough to know that the symbol for Apple is AAPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The current share price of Apple (AAPL) is $268.81."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "instructions = \"You answer questions about the stock market.\"\n",
    "request = \"What's the share price of Apple?\"\n",
    "model = \"gpt-4.1-mini\"\n",
    "\n",
    "async with MCPServerStdio(params=params, client_session_timeout_seconds=60) as mcp_server:\n",
    "    agent = Agent(name=\"agent\", instructions=instructions, model=model, mcp_servers=[mcp_server])\n",
    "    with trace(\"conversation\"):\n",
    "        result = await Runner.run(agent, request)\n",
    "    display(Markdown(result.final_output))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
